{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI & Machine Learning (KAN-CINTO4003U) - Copenhagen Business School | Spring 2025**\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Part III: LLM\n",
    "\n",
    "Please see the description of the assignment in the README file (section 3) <br>\n",
    "**Guide notebook**: [guides/llm_guide.ipynb](guides/llm_guide.ipynb)\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "<br>\n",
    "\n",
    "* Note that you should report results using a classification report. \n",
    "\n",
    "* Also, remember to include some reflections on your results: how do they compare with the results from Part I, BoW?, and part II, BERT? Are there any hyperparameters or prompting techniques that are particularly important?\n",
    "\n",
    "* You should follow the steps given in the `llm_guide` notebook\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for the project\n",
    "from sklearn.metrics import classification_report \n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data\n",
    "\n",
    "We can load this data directly from [Hugging Face Datasets](https://huggingface.co/docs/datasets/) - The HuggingFace Hub- into a Pandas DataFrame. Pretty neat!\n",
    "\n",
    "**Note**: This cell will download the dataset and keep it in memory. If you run this cell multiple times, it will download the dataset multiple times.\n",
    "\n",
    "You are welcome to increase the `frac` parameter to load more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "splits = {'train': 'data/train-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
    "# train = pd.read_parquet(\"hf://datasets/fancyzhx/ag_news/\" + splits[\"train\"])\n",
    "test = pd.read_parquet(\"hf://datasets/fancyzhx/ag_news/\" + splits[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((760, 2),)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {\n",
    "    0: 'World',\n",
    "    1: 'Sports',\n",
    "    2: 'Business',\n",
    "    3: 'Sci/Tech'\n",
    "}\n",
    "\n",
    "def preprocess(df: pd.DataFrame, frac = 0.4, label_map = label_map, seed=42) -> pd.DataFrame:\n",
    "    return  (\n",
    "        df\n",
    "        .assign(label=lambda x: x['label'].map(label_map))\n",
    "        [lambda df: df['label'].isin(label_map.values())]\n",
    "        .groupby('label')\n",
    "        .apply(lambda x: x.sample(frac=frac, random_state=seed))\n",
    "        .reset_index(drop=True)\n",
    "\n",
    "    )\n",
    "\n",
    "# train_df = preprocess(train, frac=0.01)\n",
    "test_df = preprocess(test, frac=0.1)\n",
    "\n",
    "# clear up some memory by deleting the original dataframes\n",
    "# del train\n",
    "del test\n",
    "\n",
    "test_df.shape, # train_df.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory set to: /Users/mikkel/Library/CloudStorage/OneDrive-Personligt/CBS/Cand Merc IT/2. Semester/AI and ML/mas/ma2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 760/760 [04:34<00:00,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Business       0.54      0.91      0.68       190\n",
      "    Sci/Tech       0.89      0.35      0.50       190\n",
      "      Sports       0.96      0.91      0.94       190\n",
      "       World       0.80      0.78      0.79       190\n",
      "\n",
      "    accuracy                           0.74       760\n",
      "   macro avg       0.80      0.74      0.73       760\n",
      "weighted avg       0.80      0.74      0.73       760\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Setup watsonx\n",
    "from decouple import Config\n",
    "from ibm_watsonx_ai import APIClient\n",
    "from ibm_watsonx_ai import Credentials\n",
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure the working directory is set to the \"ma2\" folder.\n",
    "while Path.cwd().name != \"ma2\" and \"ma2\" in str(Path.cwd()):\n",
    "    os.chdir(\"..\")  # Move up one directory\n",
    "print(f\"Working directory set to: {Path.cwd()}\")\n",
    "\n",
    "config = Config('.env')\n",
    "WX_API_KEY = config('WX_API_KEY')\n",
    "\n",
    "credentials = Credentials(\n",
    "                url = \"https://us-south.ml.cloud.ibm.com\",\n",
    "                api_key = WX_API_KEY\n",
    "                )\n",
    "\n",
    "client = APIClient(\n",
    "                credentials=credentials, \n",
    "                project_id=\"163839a7-17ed-4d45-8690-531423735ab8\"\n",
    "                )\n",
    "\n",
    "model = ModelInference(\n",
    "    api_client=client,\n",
    "    model_id=\"ibm/granite-13b-instruct-v2\",\n",
    ")\n",
    "\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You task is to classify news stories into one of five categories\n",
    "\n",
    "CATEGORIES:\n",
    "{categories}\n",
    "\n",
    "TEXT:\n",
    "{text}\n",
    "\n",
    "Please assign the correct category to the text. Answer with the correct category and nothing else.\n",
    "\n",
    "Category:\n",
    "\"\"\"\n",
    "\n",
    "CATEGORIES = \"- \" + \"\\n- \".join(test_df[\"label\"].unique())  # Create a string with all categories\n",
    "\n",
    "predictions = []\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for text in tqdm(test_df[\"text\"]):\n",
    "\n",
    "    # format the prompt with the categories and the text\n",
    "    prompt = SYSTEM_PROMPT.format(categories=CATEGORIES, text=text)\n",
    "    \n",
    "    # generate the response from the model\n",
    "    response = model.generate(prompt)\n",
    "\n",
    "    # extract the generated text from the response\n",
    "    prediction = response[\"results\"][0][\"generated_text\"].strip()\n",
    "\n",
    "    # append the prediction to the list of predictions\n",
    "    predictions.append(prediction)\n",
    "    \n",
    "    \n",
    "print(classification_report(test_df.label, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 760/760 [04:06<00:00,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Business       0.52      0.93      0.67       190\n",
      "    Sci/Tech       0.93      0.29      0.45       190\n",
      "      Sports       0.95      0.86      0.91       190\n",
      "       World       0.81      0.81      0.81       190\n",
      "\n",
      "    accuracy                           0.72       760\n",
      "   macro avg       0.80      0.72      0.71       760\n",
      "weighted avg       0.80      0.72      0.71       760\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with improved prompt\n",
    "SYSTEM_PROMPT = \"\"\"You are an expert news classifier. Your task is to classify news stories into one of four categories.\n",
    "\n",
    "4 CATEGORIES:\n",
    "{categories}\n",
    "\n",
    "CATEGORY DESCRIPTIONS:\n",
    "- World: International news, politics, diplomacy, global events, wars, peace talks, foreign relations\n",
    "- Sports: Athletic competitions, games, players, teams, tournaments, sports business\n",
    "- Business: Corporate news, finance, markets, mergers, acquisitions, economic data\n",
    "- Sci/Tech: Scientific discoveries, technology innovations, research, space exploration, gadgets\n",
    "\n",
    "TEXT TO CLASSIFY:\n",
    "{text}\n",
    "\n",
    "Please assign the correct category to the text. Answer with the correct category and nothing else. Remember, there are only four categories.\n",
    "\n",
    "\n",
    "CATEGORY:\n",
    "\"\"\"\n",
    "\n",
    "# Reset predictions list for new results\n",
    "predictions = []\n",
    "\n",
    "for text in tqdm(test_df[\"text\"]):\n",
    "\n",
    "    # format the prompt with the categories and the text\n",
    "    prompt = SYSTEM_PROMPT.format(categories=CATEGORIES, text=text)\n",
    "    \n",
    "    # generate the response from the model\n",
    "    response = model.generate(prompt)\n",
    "\n",
    "    # extract the generated text from the response\n",
    "    prediction = response[\"results\"][0][\"generated_text\"].strip()\n",
    "\n",
    "    # append the prediction to the list of predictions\n",
    "    predictions.append(prediction)\n",
    "    \n",
    "    \n",
    "print(classification_report(test_df.label, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 760/760 [04:34<00:00,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Business       0.57      0.89      0.70       190\n",
      "    Sci/Tech       0.90      0.38      0.54       190\n",
      "      Sports       0.95      0.93      0.94       190\n",
      "       World       0.80      0.83      0.82       190\n",
      "\n",
      "    accuracy                           0.76       760\n",
      "   macro avg       0.81      0.76      0.75       760\n",
      "weighted avg       0.81      0.76      0.75       760\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with improved prompt\n",
    "SYSTEM_PROMPT = \"\"\"You are an expert news classifier. Your task is to classify news stories into one of four categories.\n",
    "\n",
    "4 CATEGORIES:\n",
    "{categories}\n",
    "\n",
    "CATEGORY DESCRIPTIONS:\n",
    "- World: International news, politics, diplomacy, global events, wars, peace talks, foreign relations\n",
    "- Sports\n",
    "- Business: Corporate news, finance, markets, mergers, acquisitions, economic data\n",
    "- Sci/Tech\n",
    "\n",
    "TEXT TO CLASSIFY:\n",
    "{text}\n",
    "\n",
    "Please assign the correct category to the text. Answer with the correct category and nothing else. Remember, there are only four categories.\n",
    "\n",
    "\n",
    "CATEGORY:\n",
    "\"\"\"\n",
    "\n",
    "# Reset predictions list for new results\n",
    "predictions = []\n",
    "\n",
    "for text in tqdm(test_df[\"text\"]):\n",
    "\n",
    "    # format the prompt with the categories and the text\n",
    "    prompt = SYSTEM_PROMPT.format(categories=CATEGORIES, text=text)\n",
    "    \n",
    "    # generate the response from the model\n",
    "    response = model.generate(prompt)\n",
    "\n",
    "    # extract the generated text from the response\n",
    "    prediction = response[\"results\"][0][\"generated_text\"].strip()\n",
    "\n",
    "    # append the prediction to the list of predictions\n",
    "    predictions.append(prediction)\n",
    "    \n",
    "    \n",
    "print(classification_report(test_df.label, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 760/760 [04:39<00:00,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Business       0.70      0.93      0.80       190\n",
      "    Sci/Tech       0.93      0.61      0.73       190\n",
      "      Sports       0.97      0.98      0.98       190\n",
      "       World       0.90      0.91      0.90       190\n",
      "\n",
      "    accuracy                           0.86       760\n",
      "   macro avg       0.87      0.86      0.85       760\n",
      "weighted avg       0.87      0.86      0.85       760\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with new model\n",
    "model = ModelInference(\n",
    "    api_client=client,\n",
    "    model_id=\"mistralai/mistral-large\",\n",
    ")\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are an expert news classifier. Your task is to classify news stories into one of four categories.\n",
    "\n",
    "4 CATEGORIES:\n",
    "{categories}\n",
    "\n",
    "CATEGORY DESCRIPTIONS:\n",
    "- World: International news, politics, diplomacy, global events, wars, peace talks, foreign relations\n",
    "- Sports\n",
    "- Business: Corporate news, finance, markets, mergers, acquisitions, economic data\n",
    "- Sci/Tech\n",
    "\n",
    "TEXT TO CLASSIFY:\n",
    "{text}\n",
    "\n",
    "Please assign the correct category to the text. Answer with the correct category and nothing else. Remember, there are only four categories.\n",
    "\n",
    "\n",
    "CATEGORY:\n",
    "\"\"\"\n",
    "\n",
    "# Reset predictions list for new results\n",
    "predictions = []\n",
    "\n",
    "for text in tqdm(test_df[\"text\"]):\n",
    "\n",
    "    # format the prompt with the categories and the text\n",
    "    prompt = SYSTEM_PROMPT.format(categories=CATEGORIES, text=text)\n",
    "    \n",
    "    # generate the response from the model\n",
    "    response = model.generate(prompt)\n",
    "\n",
    "    # extract the generated text from the response\n",
    "    prediction = response[\"results\"][0][\"generated_text\"].strip()\n",
    "\n",
    "    # append the prediction to the list of predictions\n",
    "    predictions.append(prediction)\n",
    "    \n",
    "    \n",
    "print(classification_report(test_df.label, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the best-rated model for classification (mistral large) according to IBM metrics I was able to achieve the highest score of all measured across all metrics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
